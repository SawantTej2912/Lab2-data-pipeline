
# Lab 2 ‚Äì End-to-End Crypto Analytics Pipeline  
### Snowflake ‚Ä¢ Apache Airflow ‚Ä¢ dbt ‚Ä¢ Preset (BI Dashboard)

This project implements a full **data engineering + ELT + analytics** pipeline for cryptocurrency price analytics using:

- **Apache Airflow** for ETL orchestration  
- **Snowflake** for cloud warehousing  
- **dbt** for transformations, testing, and snapshots  
- **Preset (Apache Superset)** for data visualization  
- **yfinance** as the data source for BTC-USD and ETH-USD  

This Lab-2 project extends concepts from **Lab-1: Stock Price Predictor using Snowflake**, originally implemented by my teammate **Vaheedur Rehman**, and builds a more complete ELT workflow.

---

## üìå Project Overview

Cryptocurrency markets generate continuous and highly volatile price data.  
This project builds an automated pipeline to:

1. **Ingest raw crypto OHLCV data** (BTC-USD & ETH-USD)
2. **Store it in Snowflake RAW schema**
3. **Transform it with dbt** into analytics-ready models
4. **Run data tests**
5. **Snapshot historical data** for versioning
6. **Visualize insights** using Preset dashboards

This delivers a modern, production-style data stack with automation, quality checks, and BI reporting.

---

## üèóÔ∏è System Architecture

```

```
  +-------------------------+
  |      yfinance API       |
  +-----------+-------------+
              |
              v
  +-----------+-------------+
  |   Airflow ETL DAG       |
  | fetch_crypto_data_dag   |
  +-----------+-------------+
              |
              v
RAW Layer: PARROT_RAW.CRYPTO_PRICES
              |
        (dbt run/test)
              |
              v
FEAT Layer: PARROT_FEAT staging + features
              |
              v
```

MART Layer: PARROT_FEAT.MART_CRYPTO_SUMMARY   <--- Dashboard uses this
|
(dbt snapshot)
|
v
SNAP Layer: PARROT_SNAP.CRYPTO_PRICES_SNAPSHOT
|
v
Preset / Superset Dashboard

```

---

## üß© Components

### **1. Airflow ETL ‚Äì `fetch_crypto_data_dag.py`**
- Fetches daily OHLCV data for BTC-USD and ETH-USD  
- Cleans and normalizes data  
- Writes to temporary CSV  
- Loads into Snowflake with **MERGE** (idempotent)  
- Stores in:

```

USER_DB_PARROT.PARROT_RAW.CRYPTO_PRICES

````

**Includes:**
- Try/except error handling  
- SQL transaction control  
- Data quality checks (row counts, null checks)

---

### **2. dbt ELT Pipeline ‚Äì `crypto_analytics_dbt`**

dbt transforms RAW data into analytics-ready tables.

#### ‚úî Models:

| Layer | Schema | Table | Description |
|------|--------|--------|-------------|
| RAW | PARROT_RAW | CRYPTO_PRICES | Raw OHLCV crypto data |
| STAGING | PARROT_FEAT | STG_CRYPTO_PRICES | Cleaned, typed staging data |
| FEATURE | PARROT_FEAT | INT_CRYPTO_FEATURES | SMA5/20/50, momentum |
| MART ‚≠ê | PARROT_FEAT | MART_CRYPTO_SUMMARY | Final BI-ready table |
| SNAPSHOT | PARROT_SNAP | CRYPTO_PRICES_SNAPSHOT | Historical versioning |

#### ‚úî Tests:
- `symbol` not null  
- `price_date` not null  
- dbt schema tests for all layers  

#### ‚úî Snapshot:
```sql
CRYPTO_PRICES_SNAPSHOT
````

Tracks historical price changes using `INGESTED_AT`.

---

## ‚öôÔ∏è **3. Airflow dbt Pipeline ‚Äì `dbt_crypto_dag.py`**

Automates dbt execution:

1. `dbt run`
2. `dbt test`
3. `dbt snapshot`

Each command runs inside a PythonOperator with **try/except** for clean failure handling and logging.

Runs daily after ETL.

---

## üóÇÔ∏è Snowflake Schemas Used

```
USER_DB_PARROT.PARROT_RAW     ‚Äì Raw crypto OHLCV data  
USER_DB_PARROT.PARROT_FEAT    ‚Äì Staging, features, marts  
USER_DB_PARROT.PARROT_SNAP    ‚Äì Snapshots
```

### ‚≠ê Final analytics table for BI:

```
USER_DB_PARROT.PARROT_FEAT.MART_CRYPTO_SUMMARY
```

---

## üìä Dashboard (Preset / Superset)

Preset visualizes the final mart table.

### ‚úî Dataset:

```
PARROT_FEAT.MART_CRYPTO_SUMMARY
```

### Dashboard includes:

* Line chart: Close price + SMA5 + SMA20 + SMA50
* Momentum 5-day % chart
* Bullish signal indicator (SMA5 > SMA20)
* Filters:

  * Symbol (BTC/ETH)
  * Date range

### Required screenshots:

1. Full dashboard
2. Dashboard with filters applied (different date range or symbol)

---

## üóÇÔ∏è Repository Structure

```
lab2_repo/
‚îÇ
‚îú‚îÄ‚îÄ fetch_crypto_data_dag.py
‚îú‚îÄ‚îÄ dbt_crypto_dag.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ crypto_prices_snapshot.sql
‚îî‚îÄ‚îÄ README.md
```

---

## ‚ñ∂Ô∏è How to Run the Project

### **1. Start Airflow**

```bash
docker compose up -d
```

### **2. Run ETL**

Airflow UI ‚Üí
`fetch_crypto_data_dag` ‚Üí **Trigger DAG**

### **3. Run dbt Pipeline**

Airflow UI ‚Üí
`dbt_crypto_pipeline` ‚Üí **Trigger DAG**

### **4. Verify in Snowflake**

```sql
USE DATABASE USER_DB_PARROT;
USE SCHEMA PARROT_FEAT;
SELECT * FROM MART_CRYPTO_SUMMARY LIMIT 20;
```

### **5. Build Dashboard**

Connect Preset ‚Üí Add dataset ‚Üí Create charts.

---

## üìò Example SQL Queries

```sql
-- BTC trend (mart layer)
SELECT *
FROM PARROT_FEAT.MART_CRYPTO_SUMMARY
WHERE SYMBOL='BTC-USD'
ORDER BY PRICE_DATE DESC;

-- Compare RAW vs FEATURE
SELECT r.SYMBOL, r.PRICE_DATE, r.CLOSE AS RAW_CLOSE,
       f.SMA_20, f.MOMENTUM_5D_PCT
FROM PARROT_RAW.CRYPTO_PRICES r
JOIN PARROT_FEAT.INT_CRYPTO_FEATURES f
  ON r.SYMBOL=f.SYMBOL
 AND r.PRICE_DATE=f.PRICE_DATE
ORDER BY PRICE_DATE DESC;
```

---

## üìö References

* YFinance: [https://pypi.org/project/yfinance/](https://pypi.org/project/yfinance/)
* Apache Airflow: [https://airflow.apache.org/docs/](https://airflow.apache.org/docs/)
* dbt Docs: [https://docs.getdbt.com/](https://docs.getdbt.com/)
* Snowflake Docs: [https://docs.snowflake.com/](https://docs.snowflake.com/)
* Preset/Superset: [https://preset.io](https://preset.io)

---

## üë• Authors

* **Tejas Sawant** ‚Äì Lab 2 Development
* **Vaheedur Rehman** ‚Äì Lab 1 Foundation (Referenced)
* Department of Applied Data Intelligence
* San Jose State University

